% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/optimSPAN.R
\name{optimSPAN}
\alias{objSPAN}
\alias{optimSPAN}
\title{Optimization of sample configurations for variogram and spatial trend
identification and estimation, and for spatial interpolation}
\usage{
optimSPAN(points, candi, covars, strata.type = "area", use.coords = FALSE,
  lags = 7, lags.type = "exponential", lags.base = 2, cutoff,
  criterion = "distribution", distri, pairs = FALSE,
  schedule = scheduleSPSANN(), plotit = FALSE, track = FALSE, boundary,
  progress = TRUE, verbose = FALSE, weights = list(CORR = 1/6, DIST = 1/6,
  PPL = 1/3, MSSD = 1/3), nadir = list(sim = NULL, seeds = NULL, user = NULL,
  abs = NULL), utopia = list(user = NULL, abs = NULL))

objSPAN(points, candi, covars, strata.type = "area", use.coords = FALSE,
  lags = 7, lags.type = "exponential", lags.base = 2, cutoff,
  criterion = "distribution", distri, pairs = FALSE, x.max, x.min, y.max,
  y.min, weights = list(CORR = 1/6, DIST = 1/6, PPL = 1/3, MSSD = 1/3),
  nadir = list(sim = NULL, seeds = NULL, user = NULL, abs = NULL),
  utopia = list(user = NULL, abs = NULL))
}
\arguments{
\item{points}{Integer value, integer vector, data frame or matrix. If
\code{points} is an integer value, it defines the number of points that
should be randomly sampled from \code{candi} to form the starting system
configuration. If \code{points} is a vector of integer values, it contains
the row indexes of \code{candi} that correspond to the points that form the
starting system configuration. If \code{points} is a data frame or matrix,
it must have three columns in the following order: \code{[, "id"]} the
row indexes of \code{candi} that correspond to each point, \code{[, "x"]}
the projected x-coordinates, and \code{[, "y"]} the projected y-coordinates.
Note that in the later case, \code{points} must be a subset of \code{candi}.}

\item{candi}{Data frame or matrix with the candidate locations for the
jittered points. \code{candi} must have two columns in the following
order: \code{[, "x"]} the projected x-coordinates, and \code{[, "y"]} the
projected y-coordinates.}

\item{covars}{Data frame or matrix with the covariates in the columns.}

\item{strata.type}{Character value setting the type of stratification that
should be used to create the marginal sampling strata (or factor levels) for
the numeric covariates. Available options are \code{"area"}, for equal-area,
and \code{"range"}, for equal-range. Defaults to \code{strata.type = "area"}.}

\item{use.coords}{Logical value. Should the geographic coordinates be used
as covariates? Defaults to \code{use.coords = FALSE}.}

\item{lags}{Integer value; the number of lag-distance classes. Alternatively,
a vector of numeric values with the lower and upper bounds of each
lag-distance class, the lowest value being larger than zero (e.g. 0.0001).
Defaults to \code{lags = 7}.}

\item{lags.type}{Character value; the type of lag-distance classes, with
options \code{"equidistant"} and \code{"exponential"}. Defaults to
\code{lags.type = "exponential"}.}

\item{lags.base}{Numeric value; base of the exponential expression used to
create exponentially spaced lag-distance classes. Used only when
\code{lags.type = "exponential"}. Defaults to \code{lags.base = 2}.}

\item{cutoff}{Numeric value; the maximum distance up to which lag-distance
classes are created. Used only when \code{lags} is an integer value. If
missing, it is set to be equal to the length of the diagonal of the rectagle
with sides \code{x.max} and \code{y.max} as defined in
\code{\link[spsann]{scheduleSPSANN}}.}

\item{criterion}{Character value; the feature used to describe the
energy state of the system configuration, with options \code{"minimum"} and
\code{"distribution"}. Defaults to \code{objective = "distribution"}.}

\item{distri}{Numeric vector; the distribution of points or point-pairs per
lag-distance class that should be attained at the end of the optimization.
Used only when \code{criterion = "distribution"}. Defaults to a uniform
distribution.}

\item{pairs}{Logical value; should the sample configuration be optimized
regarding the number of point-pairs per lag-distance class? Defaults to
\code{pairs = FALSE}.}

\item{schedule}{List with 11 named sub-arguments defining the control
parameters of the cooling schedule. See \code{\link[spsann]{scheduleSPSANN}}.}

\item{plotit}{Logical for plotting the optimization results, including
a) the progress of the objective function, and b) the starting (gray) and
current system configuration (black), and the maximum jitter in the
x- and y-coordinates. The plots are updated at each 10 jitters. Defaults to
\code{plotit = FALSE}.}

\item{track}{Logical value. Should the evolution of the energy state be
recorded and returned with the result? If \code{track = FALSE} (the default),
only the starting and ending energy states are returned with the results.}

\item{boundary}{SpatialPolygon defining the boundary of the spatial domain.
If missing and \code{plotit = TRUE}, \code{boundary} is estimated from
\code{candi}.}

\item{progress}{Logical for printing a progress bar. Defaults to
\code{progress = TRUE}.}

\item{verbose}{Logical for printing messages about the progress of the
optimization. Defaults to \code{verbose = FALSE}.}

\item{weights}{List with named sub-arguments. The weights assigned to each
one of the objective functions that form the multi-objective optimization
problem (MOOP). They must be named after the respective objective function
to which they apply. The weights must be equal to or larger than 0 and sum
to 1. The default option gives equal weights to all objective functions.}

\item{nadir}{List with named sub-arguments. Three options are available:
1) \code{sim} -- the number of simulations that should be used to estimate
the nadir point, and \code{seeds} -- vector defining the random seeds for
each simulation; 2) \code{user} -- a list of user-defined nadir values named
after the respective objective functions to which they apply; 3) \code{abs}
-- logical for calculating the nadir point internally (experimental).}

\item{utopia}{List with named sub-arguments. Two options are available: 1)
\code{user} -- a list of user-defined values named after the respective
objective functions to which they apply; 2) \code{abs} -- logical for
calculating the utopia point internally (experimental).}

\item{x.max}{Numeric value defining the minimum and
maximum quantity of random noise to be added to the projected x- and
y-coordinates. The minimum quantity should be equal to, at least, the
minimum distance between two neighbouring candidate locations. The units
are the same as of the projected x- and y-coordinates. If missing, they
are estimated from \code{candi}.}

\item{x.min}{Numeric value defining the minimum and
maximum quantity of random noise to be added to the projected x- and
y-coordinates. The minimum quantity should be equal to, at least, the
minimum distance between two neighbouring candidate locations. The units
are the same as of the projected x- and y-coordinates. If missing, they
are estimated from \code{candi}.}

\item{y.max}{Numeric value defining the minimum and
maximum quantity of random noise to be added to the projected x- and
y-coordinates. The minimum quantity should be equal to, at least, the
minimum distance between two neighbouring candidate locations. The units
are the same as of the projected x- and y-coordinates. If missing, they
are estimated from \code{candi}.}

\item{y.min}{Numeric value defining the minimum and
maximum quantity of random noise to be added to the projected x- and
y-coordinates. The minimum quantity should be equal to, at least, the
minimum distance between two neighbouring candidate locations. The units
are the same as of the projected x- and y-coordinates. If missing, they
are estimated from \code{candi}.}
}
\value{
\code{optimSPAN()} returns a matrix: the optimized sample configuration.

\code{objSPAN} returns a numeric value: the energy state of the sample
configuration - the objective function value.
}
\description{
Optimize a sample configuration for variogram and spatial trend
identification and estimation, and for spatial interpolation. An utility
function \emph{U} is defined so that the sample points cover, extend over,
spread over, \bold{SPAN} the feature, variogram and geographic spaces. The
utility function is obtained aggregating four single objective functions:
\bold{CORR}, \bold{DIST}, \bold{PPL}, and \bold{MSSD}.
}
\section{Jittering methods}{

There are two ways of jittering the coordinates. They differ on how the
set of candidate locations is defined. The first method uses an
\emph{infinite} set of candidate locations, that is, any locations in the
spatial domain can be selected as the new location of a jittered point. All
that this method needs is a polygon indicating the boundary of the spatial
domain. This method is not implemented in the \pkg{spsann}-package because
it is computationally demanding: every time a point is jittered, it is
necessary to check if the point is inside the spatial domain.

The second method consists of using a \emph{finite} set of candidate
locations for the jittered points. A finite set of candidate locations is
created by discretizing the spatial domain, that is, creating a fine grid of
points that serve as candidate locations for the jittered points. This is
the least computationally demanding jittering method because, by definition,
the jittered point will always be inside the spatial domain. However, not
all locations in the spatial domain can be selected as the new location for
a jittered point.

Using a finite set of candidate locations has another important
inconvenience. When a point is jittered, it may be that the new location
already is occupied by another point. If this happens, another location has
to be iteratively sought for, say, as many times as the number of points in
the system. In general, the more points there are in the system, the more
likely it is that the new location already is occupied by another point. If
a solution is not found in a reasonable time, the point selected to be
jittered is kept in its original location. Such a proceedure is clearly
suboptimal.

The \pkg{spsann}-package uses a more elegant method which is based on using
a finite set of candidate locations coupled with a form of \emph{two-stage
random sampling} as implemented in \code{\link[spcosa]{spsample}}. Because
the candidate locations are placed on a finite regular grid, they can be
seen as being the centre nodes of a finite set of grid cells (or pixels of
a raster image). In the first stage, one of the \dQuote{grid cells} is
selected with replacement, i.e. independently of already being occupied by
another sample point. The new location for the point chosen to be jittered
is selected within that \dQuote{grid cell} by simple random sampling. This
method guarantees that \emph{almost} any location in the spatial domain can
be a candidate location. It also discards the need to check if the new
location already is occupied by another point, simplifying the code and
(possibly) speeding up the computations.
}

\section{Distance between two points}{

The distance between two points is computed as the Euclidean distance between
them. This computation assumes that the optimization is operating in the
two-dimensional Euclidean space, i.e. the coordinates of the sample points
and candidate locations should not be provided as latitude/longitude. Package
\pkg{spsann} has no mechanism to check if the coordinates are projected, and
the user is responsible for making sure that this requirement is attained.
}

\section{Multi-objective optimization}{

A method of solving a multi-objective optimization problem is to aggregate
the objective functions into a single \emph{utility function}. In the
\pkg{spsann}-package, the aggregation is performed using the \emph{weighted
sum method}, which incorporates in the weights the preferences of the user
regarding the relative importance of each objective function.

The weighted sum method is affected by the relative magnitude of the
different function values. The objective functions implemented in the
\pkg{spsann}-package have different units and orders of magnitude. The
consequence is that the objective function with the largest values will have
a numerical dominance in the optimization. In other words, the weights will
not express the true preferences of the user, and the meaning of the utility
function becomes unclear.

A solution to avoid the numerical dominance is to transform the objective
functions so that they are constrained to the same approximate range of
values. Several function-transformation methods can be used and the
\pkg{spsann}-package offers a few of them. The \emph{upper-lower-bound
approach} requires the user to inform the maximum (nadir point) and minimum
(utopia point) absolute function values. The resulting function values will
always range between 0 and 1.

Using the \emph{upper-bound approach} requires the user to inform only the
nadir point, while the utopia point is set to zero. The upper-bound approach
for transformation aims at equalizing only the upper bounds of the objective
functions. The resulting function values will always be smaller than or equal
to 1.

Sometimes, the absolute maximum and minimum values of an objective function
can be calculated exactly. This seems not to be the case of the objective
functions implemented in the \pkg{spsann}-package. If the user is
uncomfortable with informing the nadir and utopia points, there is the option
for using \emph{numerical simulations}. It consists of computing the
function value for many random sample configurations. The mean function
value is used to set the nadir point, while the the utopia point is set to
zero. This approach is similar to the upper-bound approach, but the function
values will have the same orders of magnitude only at the starting point of
the optimization. Function values larger than one are likely to occur during
the optimization. We recommend the user to avoid this approach whenever
possible because the effect of the starting point on the optimization as a
whole usually is insignificant or arbitrary.

The \emph{upper-lower-bound approach} with the \emph{Pareto maximum and
minimum values} is the most elegant solution to transform the objective
functions. However, it is the most time consuming. It works as follows:

\enumerate{
  \item Optimize a sample configuration with respect to each objective
  function that composes the MOOP;
  \item Compute the function value of every objective function that composes
  the MOOP for every optimized sample configuration;
  \item Record the maximum and minimum absolute function values computed for
  each objective function that composes the MOOP -- these are the Pareto
  maximum and minimum.
}

For example, consider that a MOOP is composed of two objective functions: A
and B. The minimum absolute value for function A is obtained when the sample
configuration is optimized with respect to function A. This is the Pareto
minimum of function A. Consequently, the maximum absolute value for function
A is obtained when the sample configuration is optimized regarding function
B. This is the Pareto maximum of function A. The same logic applies for
function B.
}

\section{Association/Correlation between covariates}{

The \emph{correlation} between two numeric covariates is measured using the
Pearson's \emph{r}, a descriptive statistic that ranges from $-1$ to $+1$.
This statistic is also known as the linear correlation coefficient.

When the set of covariates includes factor covariates, all numeric covariates
are transformed into factor covariates. The factor levels are defined
using the marginal sampling strata created from one of the two methods
available (equal-area or equal-range strata).

The \emph{association} between two factor covariates is measured using the
Cramér's \emph{v}, a descriptive statistic that ranges from $0$ to $+1$. The
closer to $+1$ the Cramér's \emph{v} is, the stronger the association between
two factor covariates. The main weakness of using the Cramér's \emph{v} is
that, while the Pearson's \emph{r} shows the degree and direction of the
association between two covariates (negative or positive), the Cramér's
\emph{v} only measures the degree of association (weak or strong).
}

\section{Marginal distribution of covariates}{

Reproducing the marginal distribution of the numeric covariates depends upon
the definition of marginal sampling strata. These marginal sampling strata
are also used to define the factor levels of all numeric covariates that
are passed together with factor covariates. Two types of marginal sampling
strata can be used: \emph{equal-area} and \emph{equal-range}.

\subsection{Equal-area}{
\emph{Equal-area} marginal sampling strata are defined using the sample
quantiles estimated with \code{\link[stats]{quantile}} using a discontinuous
function (\code{type = 3}). This is to avoid creating breakpoints that do
not occur in the population of existing covariate values.

Depending on the level of discretization of the covariate values,
\code{\link[stats]{quantile}} produces repeated breakpoints. A breakpoint
will be repeated if that value has a relatively high frequency in the
population of covariate values. The number of repeated breakpoints increases
with the number of marginal sampling strata. Repeated breakpoints result in
empty marginal sampling strata. To avoid this, only the unique breakpoints
are used.
}
\subsection{Equal-range}{
\emph{Equal-range} marginal sampling strata are defined by breaking the range
of covariate values into pieces of equal size. Depending on the level of
discretization of the covariate values, this method creates breakpoints that
do not occur in the population of existing covariate values. Such breakpoints
are replaced by the nearest existing covariate value identified using
Euclidean distances.

Like the equal-area method, the equal-range method can produce empty marginal
sampling strata. The solution used here is to merge any empty marginal
sampling strata with the closest non-empty marginal sampling strata. This is
identified using Euclidean distances as well.
}

The approaches used to define the marginal sampling strata result in each
numeric covariate having a different number of marginal sampling strata,
some of them with different area/size. Because the goal is to have a sample
that reproduces the marginal distribution of the covariate, each marginal
sampling strata will have a different number of sample points. The wanted
distribution of the number of sample points per marginal strata is estimated
empirically as the proportion of points in the population of existing
covariate values that fall in each marginal sampling strata.
}

\section{Lag-distance classes}{

Two types of lag-distance classes can be created by default. The first are
evenly spaced lags (\code{lags.type = "equidistant"}). They are created by
simply dividing the distance interval from 0.0001 to \code{cutoff} by the
required number of lags. The minimum value of 0.0001 guarantees that a
point does not form a pair with itself. The second type of lags is defined by
exponential spacings (\code{lags.type = "exponential"}). The spacings are
defined by the base \eqn{b} of the exponential expression \eqn{b^n}, where
\eqn{n} is the required number of lags. The base is defined using the
argument \code{lags.base}. See \code{\link[pedometrics]{vgmLags}} for other
details.

Using the default uniform distribution means that the
number of point-pairs per lag-distance class (\code{pairs = TRUE}) is equal
to \eqn{n \times (n - 1) / (2 \times lag)}, where \eqn{n} is the total number
of points and \eqn{lag} is the number of lags. If \code{pairs = FALSE}, then
it means that the number of points per lag is equal to the total number of
points. This is the same as expecting that each point contributes to every
lag. Distributions other than the available options can be easily
implemented changing the arguments \code{lags} and \code{distri}.

There are two optimizing criteria implemented. The first is called
using \code{criterion = "distribution"} and is used to minimize the
sum of the absolute differences between a pre-specified distribution and the
observed distribution of points or point-pairs per lag-distance class. The
second criterion is called using \code{criterion = "minimum"}. It corresponds
to maximizing the minimum number of points or point-pairs observed over all
lag-distance classes.
}

\section{Spatial coverage sampling}{

Spatial coverage sampling is based on the knowledge that the kriging variance
depends upon the distance between the sample points. As such, the better the
spread of the sample points in the spatial domain, the smaller the kriging
variance. This is similar to using a regular grid of sample points. However,
a regular grid usually is suboptimal for irregularly shaped areas.
}
\examples{
\dontrun{
# This example takes more than 5 seconds to run!
require(sp)
data(meuse.grid)
candi <- meuse.grid[, 1:2]
nadir <- list(sim = 10, seeds = 1:10)
utopia <- list(user = list(DIST = 0, CORR = 0, PPL = 0, MSSD = 0))
covars <- meuse.grid[, 5]
schedule <- scheduleSPSANN(chains = 1, initial.temperature = 1)
set.seed(2001)
res <- optimSPAN(points = 100, candi = candi, covars = covars,
                 nadir = nadir, use.coords = TRUE, utopia = utopia,
                 schedule = schedule)
objSPSANN(res) -
  objSPAN(points = res, candi = candi, covars = covars, nadir = nadir,
          use.coords = TRUE, utopia = utopia)
}
}
\author{
Alessandro Samuel-Rosa \email{alessandrosamuelrosa@gmail.com}
}
\references{
Edzer Pebesma, Jon Skoien with contributions from Olivier Baume, A. Chorti,
D.T. Hristopulos, S.J. Melles and G. Spiliopoulos (2013).
\emph{intamapInteractive: procedures for automated interpolation - methods
only to be used interactively, not included in \code{intamap} package.} R
package version 1.1-10.

van Groenigen, J.-W. \emph{Constrained optimization of spatial sampling:
a geostatistical approach.} Wageningen: Wageningen University, p. 148, 1999.

Walvoort, D. J. J.; Brus, D. J. & de Gruijter, J. J. An R package for
spatial coverage sampling and random sampling from compact geographical
strata by k-means. \emph{Computers & Geosciences}. v. 36, p. 1261-1267, 2010.

Cramér, H. \emph{Mathematical methods of statistics}. Princeton: Princeton
University Press, p. 575, 1946.

Everitt, B. S. \emph{The Cambridge dictionary of statistics}. Cambridge:
Cambridge University Press, p. 432, 2006.

Hyndman, R. J.; Fan, Y. Sample quantiles in statistical packages. \emph{The
American Statistician}, v. 50, p. 361-365, 1996.

Minasny, B.; McBratney, A. B. A conditioned Latin hypercube method for
sampling in the presence of ancillary information. \emph{Computers &
Geosciences}, v. 32, p. 1378-1388, 2006.

Minasny, B.; McBratney, A. B. Conditioned Latin Hypercube Sampling for
calibrating soil sensor data to soil properties. Chapter 9. Viscarra Rossel,
R. A.; McBratney, A. B.; Minasny, B. (Eds.) \emph{Proximal Soil Sensing}.
Amsterdam: Springer, p. 111-119, 2010.

Roudier, P.; Beaudette, D.; Hewitt, A. A conditioned Latin hypercube sampling
algorithm incorporating operational constraints. \emph{5th Global Workshop on
Digital Soil Mapping}. Sydney, p. 227-231, 2012.

Arora, J. \emph{Introduction to optimum design}. Waltham: Academic Press, p.
896, 2011.

Marler, R. T.; Arora, J. S. Survey of multi-objective optimization methods
for engineering. \emph{Structural and Multidisciplinary Optimization}, v. 26,
p. 369-395, 2004.

Marler, R. T.; Arora, J. S. Function-transformation methods for
multi-objective optimization. \emph{Engineering Optimization}, v. 37, p.
551-570, 2005.

Marler, R. T.; Arora, J. S. The weighted sum method for multi-objective
optimization: new insights. \emph{Structural and Multidisciplinary
Optimization}, v. 41, p. 853-862, 2009.

Bresler, E.; Green, R. E. \emph{Soil parameters and sampling scheme for
characterizing soil hydraulic properties of a watershed}. Honolulu:
University of Hawaii at Manoa, p. 42, 1982.

Pettitt, A. N.; McBratney, A. B. Sampling designs for estimating spatial
variance components. \emph{Applied Statistics}. v. 42, p. 185, 1993.

Russo, D. Design of an optimal sampling network for estimating the variogram.
\emph{Soil Science Society of America Journal}. v. 48, p. 708-716, 1984.

Truong, P. N.; Heuvelink, G. B. M.; Gosling, J. P. Web-based tool for expert
elicitation of the variogram. \emph{Computers and Geosciences}. v. 51, p.
390-399, 2013.

Warrick, A. W.; Myers, D. E. Optimization of sampling locations for variogram
calculations. \emph{Water Resources Research}. v. 23, p. 496-500, 1987.
}
\concept{
simulated annealing

spatial trend

variogram
}
\keyword{iteration}
\keyword{optimize}
\keyword{spatial}

